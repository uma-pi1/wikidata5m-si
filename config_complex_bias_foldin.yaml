complex:
  class_name: ComplEx
  entity_embedder:
    +++: +++
    dropout: -0.3544049709300934
    regularize_weight: 1.6264961100212127e-10
    #type: lookup_embedder
    type: hash_lookup_embedder
  relation_embedder:
    +++: +++
    dropout: 0.49578630555558545
    regularize_weight: 8.552051698702295e-20
    type: lookup_embedder
console:
  format: {}
  quiet: false
dataset:
  name: wikidata5m_v3_semi_inductive
entity_ranking:
  chunk_size: 10000
  class_name: EntityRankingJob
  filter_splits:
  - train
  - valid
  filter_with_test: true
  hits_at_k_s:
  - 1
  - 3
  - 10
  - 50
  - 100
  - 200
  - 300
  - 400
  - 500
  - 1000
  metrics_per:
    argument_frequency: false
    head_and_tail: false
    relation_type: false
eval:
  batch_size: 128
  num_workers: 0
  pin_memory: false
  split: valid
  trace_level: epoch
  type: entity_ranking
import:
- complex
- hash_lookup_embedder
job:
  device: cuda
  type: train
hash_lookup_embedder:
  dim: 128
  partition_type: random
  num_partitions: 1
  layer_reduction_factor: 1
  dropout: 0.0
  initialize: xavier_uniform_
  initialize_args:
    +++: +++
    normal_:
      mean: 0.0
      std: 0.015600974164869342
    uniform_:
      a: -0.42509770087271137
    xavier_normal_:
      gain: 1.0
    xavier_uniform_:
      gain: 1.0
  regularize: lp
  regularize_args:
    +++: +++
    p: 3
    weighted: true
  regularize_weight: 0.0
lookup_embedder:
  class_name: LookupEmbedder
  dim: 128
  dropout: 0.0
  initialize: xavier_uniform_
  initialize_args:
    +++: +++
    normal_:
      mean: 0.0
      std: 0.015600974164869342
    uniform_:
      a: -0.42509770087271137
    xavier_normal_:
      gain: 1.0
    xavier_uniform_:
      gain: 1.0
  normalize:
    p: -1.0
  regularize: lp
  regularize_args:
    +++: +++
    p: 3
    weighted: true
  regularize_weight: 0.0
  round_dim_to: []
  sparse: true
model: complex
modules:
- kge.model
- kge.job
- kge.model.embedder
negative_sampling:
  class_name: TrainingJobNegativeSampling
  filtering:
    implementation: fast_if_available
    o: false
    p: false
    s: false
    split: ''
  frequency:
    smoothing: 1
  implementation: batch
  num_samples:
    o: 7467
    p: 0
    s: 5735
  sampling_type: uniform
  shared: true
  shared_type: default
  with_replacement: false
random_seed:
  default: 42
  numba: 42
  numpy: 42
  python: 42
  torch: 42
train:
  abort_on_nan: true
  auto_correct: true
  batch_size: 1024
  checkpoint:
    every: 0
    keep: 0
    keep_init: false
  loss: kl
  loss_arg: 1.0
  lr_scheduler: ''
  lr_scheduler_args:
    +++: +++
  lr_warmup: 0
  max_epochs: 64
  num_workers: 0
  optimizer:
    +++: +++
    default:
      args:
        +++: +++
        lr: 0.11345708649220962
      type: Adagrad
    unseen:
      args:
        +++: +++
      regex: .*unseen_embedding.*
  pin_memory: false
  split: train
  subbatch_auto_tune: false
  subbatch_size: -1
  trace_level: epoch
  type: negative_sampling
  visualize_graph: false
training_loss:
  class_name: TrainingLossEvaluationJob
user:
  +++: +++
valid:
  early_stopping:
    patience: 0
    threshold:
      epochs: 0
      metric_value: 0.0
  every: 4
  metric: mean_reciprocal_rank_filtered
  metric_expr: float("nan")
  metric_max: true
  split: valid
  trace_level: epoch
