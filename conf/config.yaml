
dataset:
  name: wikidata5m

  # use original KGT5 without context
  v1: False

  # use deprecated input format. Necessary to properly evaluate old models.
  is_legacy: False
model:
  name: t5-small
  tokenizer_type: t5
  max_input_length: 512
  max_output_length: 40
context:
  use: True
  max_size: 100
  shuffle: True

  # this "dropout" option is called context-hiding in the paper
  dropout:
    # in how many cases are we using any kind of dropout
    percentage: 0.0

    # what kind of dropout, has to sum to 1.0
    # drop complete context
    full: 0.5
    # sample context triples < max_size
    sample: 0.5
    sample_range:
      low: 1
      high: 10

descriptions:
  use: False
train:
  batch_size: 64
  max_epochs: 100
  drop_subject: 0.0
  num_workers: 4
  precision: 16
  accelerator: auto
  devices: auto
  strategy: ddp_find_unused_parameters_false
  #strategy: ddp
eval:
  num_predictions: 500
  max_length: 40
  batch_size: 1
  few_shot:
    use: False
    num_shots: 10
    context_selection: most_common
valid:
  every: 1
  tiny: True
checkpoint:
  keep_top_k: 3

resume_from: ""
wandb:
  use: False
  project_name: kgt5_context_${dataset.name}
  run_name: v1=${dataset.v1}_desc=${descriptions.use}_bs=${train.batch_size}

hydra:
  job:
    chdir: False
  run:
    dir: ./outputs/${dataset.name}/v1=${dataset.v1}/descriptions=${descriptions.use}/${now:%Y-%m-%d-%H-%M}
    #dir: ./tmp
